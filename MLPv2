import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import KFold, train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt
import warnings
from itertools import product
warnings.filterwarnings('ignore')

class MLPRegressor(nn.Module):
    def __init__(self, input_size, hidden_sizes=[64, 32], dropout_rate=0.2, activation='relu'):
        super(MLPRegressor, self).__init__()
        
        # Activation function mapping
        activations = {
            'relu': nn.ReLU(),
            'tanh': nn.Tanh(),
            'sigmoid': nn.Sigmoid(),
            'leaky_relu': nn.LeakyReLU(),
            'elu': nn.ELU(),
            'gelu': nn.GELU(),
            'swish': nn.SiLU(),  # SiLU is Swish
            'mish': nn.Mish()
        }
        
        if activation.lower() not in activations:
            print(f"Warning: '{activation}' not found. Using 'relu' instead.")
            activation = 'relu'
        
        layers = []
        prev_size = input_size
        
        # Hidden layers
        for hidden_size in hidden_sizes:
            layers.append(nn.Linear(prev_size, hidden_size))
            layers.append(activations[activation.lower()])
            layers.append(nn.Dropout(dropout_rate))
            prev_size = hidden_size
        
        # Output layer
        layers.append(nn.Linear(prev_size, 1))
        
        self.network = nn.Sequential(*layers)
    
    def forward(self, x):
        return self.network(x)

class MLPModelManager:
    def __init__(self, csv_file_path, target_column, use_log_transform=False):
        """
        Initialize MLP Model Manager
        
        Args:
            csv_file_path (str): Path to CSV file
            target_column (str): Name of target column
            use_log_transform (bool): Whether to apply log transformation before scaling
        """
        self.csv_file_path = csv_file_path
        self.target_column = target_column
        self.use_log_transform = use_log_transform
        self.data = None
        self.features = None
        self.target = None
        self.feature_scaler = None
        self.target_scaler = None
        self.model = None
        self.feature_names = None
        self.dropped_features = []
        self.training_history = {'train_losses': [], 'val_losses': []}
        self.model_metrics = {}
        
        self.load_data()
    
    def load_data(self):
        """Load data from CSV file"""
        try:
            self.data = pd.read_csv(self.csv_file_path)
            print(f"Data loaded successfully. Shape: {self.data.shape}")
            print(f"Columns: {list(self.data.columns)}")
            
            if self.target_column not in self.data.columns:
                raise ValueError(f"Target column '{self.target_column}' not found in data")
            
            # Separate features and target
            self.features = self.data.drop(columns=[self.target_column])
            self.target = self.data[self.target_column]
            self.feature_names = list(self.features.columns)
            
            print(f"Features: {self.feature_names}")
            print(f"Target: {self.target_column}")
            
        except Exception as e:
            print(f"Error loading data: {e}")
            raise
    
    def drop_features(self, features_to_drop):
        """
        Manually drop features from the dataset
        
        Args:
            features_to_drop (list): List of feature names to drop
        """
        available_features = set(self.features.columns)
        features_to_drop = [f for f in features_to_drop if f in available_features]
        
        if features_to_drop:
            self.features = self.features.drop(columns=features_to_drop)
            self.feature_names = list(self.features.columns)
            self.dropped_features.extend(features_to_drop)
            print(f"Dropped features: {features_to_drop}")
            print(f"Remaining features: {self.feature_names}")
        else:
            print("No valid features to drop")
    
    def preprocess_data(self):
        """Apply optional log transformation then standardization to both features and target"""
        
        # Prepare features
        features_data = self.features.copy()
        target_data = self.target.values.copy()
        
        if self.use_log_transform:
            print("Applying log transformation...")
            # Log transformation (add 1 to handle zeros and negatives)
            features_data = np.log1p(np.abs(features_data))
            target_data = np.log1p(np.abs(target_data))
        
        # Standardize features
        self.feature_scaler = StandardScaler()
        features_scaled = self.feature_scaler.fit_transform(features_data)
        
        # Standardize target
        self.target_scaler = StandardScaler()
        target_scaled = self.target_scaler.fit_transform(target_data.reshape(-1, 1)).flatten()
        
        return features_scaled, target_scaled
    
    def train_model(self, mode='quick', hidden_sizes=None, learning_rate=None, 
                   epochs=None, batch_size=32, dropout_rate=0.2, k_folds=5, activation='relu',
                   early_stopping=True, patience=10, min_delta=0.001, print_every=20):
        """
        Train MLP model with K-fold cross validation
        
        Args:
            mode (str): 'quick' or 'robust'
            hidden_sizes (list): Hidden layer sizes (if None, uses defaults)
            learning_rate (float): Learning rate (if None, uses defaults)
            epochs (int): Number of epochs (if None, uses defaults)
            batch_size (int): Batch size
            dropout_rate (float): Dropout rate
            k_folds (int): Number of folds for cross validation
            activation (str): Activation function ('relu', 'tanh', 'sigmoid', 'leaky_relu', 'elu', 'gelu', 'swish', 'mish')
            early_stopping (bool): Enable early stopping
            patience (int): Early stopping patience (epochs to wait)
            min_delta (float): Minimum change to qualify as improvement
            print_every (int): Print progress every N epochs
        """
        # Set defaults based on mode
        if mode == 'quick':
            hidden_sizes = hidden_sizes or [64, 32]
            learning_rate = learning_rate or 0.001
            epochs = epochs or 100
        else:  # robust mode
            hidden_sizes = hidden_sizes or [128, 64, 32]
            learning_rate = learning_rate or 0.0005
            epochs = epochs or 300
        
        print(f"Training in {mode} mode...")
        print(f"Hidden sizes: {hidden_sizes}")
        print(f"Learning rate: {learning_rate}")
        print(f"Epochs: {epochs}")
        print(f"Activation: {activation}")
        print(f"K-folds: {k_folds}")
        print(f"Early stopping: {early_stopping} (patience: {patience})")
        print(f"Progress updates every {print_every} epochs")
        
        # Preprocess data ONCE and reuse scalers
        X, y = self.preprocess_data()
        
        # Convert to tensors
        X_tensor = torch.FloatTensor(X)
        y_tensor = torch.FloatTensor(y).reshape(-1, 1)
        
        # K-fold cross validation
        kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)
        fold_results = []
        
        for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):
            print(f"\nFold {fold + 1}/{k_folds}")
            
            # Split data
            X_train_fold = X_tensor[train_idx]
            X_val_fold = X_tensor[val_idx]
            y_train_fold = y_tensor[train_idx]
            y_val_fold = y_tensor[val_idx]
            
            # Initialize model with activation
            model = MLPRegressor(X.shape[1], hidden_sizes, dropout_rate, activation)
            criterion = nn.MSELoss()
            optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)
            
            # Training loop with proper batch processing
            train_losses = []
            val_losses = []
            best_val_loss = float('inf')
            patience_counter = 0
            best_model_state = None
            
            # Create data loaders for proper batch training
            train_dataset = torch.utils.data.TensorDataset(X_train_fold, y_train_fold)
            train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
            
            for epoch in range(epochs):
                # Training phase
                model.train()
                epoch_train_loss = 0.0
                
                for batch_X, batch_y in train_loader:
                    optimizer.zero_grad()
                    outputs = model(batch_X)
                    loss = criterion(outputs, batch_y)
                    loss.backward()
                    
                    # Gradient clipping to prevent exploding gradients
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    
                    optimizer.step()
                    epoch_train_loss += loss.item()
                
                avg_train_loss = epoch_train_loss / len(train_loader)
                
                # Validation phase
                model.eval()
                with torch.no_grad():
                    val_outputs = model(X_val_fold)
                    val_loss = criterion(val_outputs, y_val_fold)
                
                train_losses.append(avg_train_loss)
                val_losses.append(val_loss.item())
                
                # Print progress
                if (epoch + 1) % print_every == 0 or epoch == 0:
                    print(f"  Epoch {epoch + 1:3d}/{epochs}: Train Loss: {avg_train_loss:.6f}, Val Loss: {val_loss.item():.6f}")
                
                # Early stopping logic
                if early_stopping:
                    if val_loss.item() < (best_val_loss - min_delta):
                        best_val_loss = val_loss.item()
                        patience_counter = 0
                        best_model_state = model.state_dict().copy()
                    else:
                        patience_counter += 1
                    
                    if patience_counter >= patience:
                        print(f"  Early stopping triggered at epoch {epoch + 1}")
                        print(f"  Best validation loss: {best_val_loss:.6f}")
                        if best_model_state is not None:
                            model.load_state_dict(best_model_state)
                        break
            
            # Calculate fold metrics - Inverse transform back to original scale
            model.eval()
            with torch.no_grad():
                train_pred_scaled = model(X_train_fold).numpy().flatten()
                val_pred_scaled = model(X_val_fold).numpy().flatten()
                
                # Inverse transform predictions and targets to original scale
                train_pred_unscaled = self.target_scaler.inverse_transform(train_pred_scaled.reshape(-1, 1)).flatten()
                val_pred_unscaled = self.target_scaler.inverse_transform(val_pred_scaled.reshape(-1, 1)).flatten()
                train_actual_unscaled = self.target_scaler.inverse_transform(y_train_fold.numpy()).flatten()
                val_actual_unscaled = self.target_scaler.inverse_transform(y_val_fold.numpy()).flatten()
                
                # If log transform was used, inverse the log transform too
                if self.use_log_transform:
                    train_pred = np.expm1(train_pred_unscaled)  # Inverse of log1p
                    val_pred = np.expm1(val_pred_unscaled)
                    train_actual = np.expm1(train_actual_unscaled)
                    val_actual = np.expm1(val_actual_unscaled)
                else:
                    train_pred = train_pred_unscaled
                    val_pred = val_pred_unscaled
                    train_actual = train_actual_unscaled
                    val_actual = val_actual_unscaled
                
                train_r2 = r2_score(train_actual, train_pred)
                val_r2 = r2_score(val_actual, val_pred)
                train_rmse = np.sqrt(mean_squared_error(train_actual, train_pred))
                val_rmse = np.sqrt(mean_squared_error(val_actual, val_pred))
            
            fold_results.append({
                'train_r2': train_r2,
                'val_r2': val_r2,
                'train_rmse': train_rmse,
                'val_rmse': val_rmse,
                'train_losses': train_losses,
                'val_losses': val_losses
            })
            
            # Final epoch summary for this fold
            final_epoch = min(epoch + 1, epochs)
            print(f"  Fold {fold + 1} completed: {final_epoch} epochs")
            print(f"  Train R²: {train_r2:.4f}, Val R²: {val_r2:.4f}")
            print(f"  Train RMSE: {train_rmse:.4f}, Val RMSE: {val_rmse:.4f}")
            
            if early_stopping and patience_counter < patience:
                print(f"  Training completed normally (no early stopping)")
            elif early_stopping:
                print(f"  Early stopped - saved {epochs - final_epoch} epochs")
        
        # Train final model on full dataset with proper batch processing
        print(f"\nTraining final model...")
        self.model = MLPRegressor(X.shape[1], hidden_sizes, dropout_rate, activation)
        criterion = nn.MSELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-5)
        
        # Final training with train/test split
        X_train, X_test, y_train, y_test = train_test_split(
            X_tensor, y_tensor, test_size=0.2, random_state=42
        )
        
        # Create data loader for final training
        final_train_dataset = torch.utils.data.TensorDataset(X_train, y_train)
        final_train_loader = torch.utils.data.DataLoader(final_train_dataset, batch_size=batch_size, shuffle=True)
        
        train_losses = []
        val_losses = []
        best_val_loss = float('inf')
        patience_counter = 0
        best_model_state = None
        
        for epoch in range(epochs):
            # Training phase
            self.model.train()
            epoch_train_loss = 0.0
            
            for batch_X, batch_y in final_train_loader:
                optimizer.zero_grad()
                outputs = self.model(batch_X)
                loss = criterion(outputs, batch_y)
                loss.backward()
                
                # Gradient clipping
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                
                optimizer.step()
                epoch_train_loss += loss.item()
            
            avg_train_loss = epoch_train_loss / len(final_train_loader)
            
            # Validation phase
            self.model.eval()
            with torch.no_grad():
                val_outputs = self.model(X_test)
                val_loss = criterion(val_outputs, y_test)
            
            train_losses.append(avg_train_loss)
            val_losses.append(val_loss.item())
            
            # Print progress for final model
            if (epoch + 1) % print_every == 0 or epoch == 0:
                print(f"Final model - Epoch {epoch + 1:3d}/{epochs}: Train Loss: {avg_train_loss:.6f}, Val Loss: {val_loss.item():.6f}")
            
            # Early stopping for final model
            if early_stopping:
                if val_loss.item() < (best_val_loss - min_delta):
                    best_val_loss = val_loss.item()
                    patience_counter = 0
                    best_model_state = self.model.state_dict().copy()
                else:
                    patience_counter += 1
                
                if patience_counter >= patience:
                    print(f"Final model early stopping at epoch {epoch + 1}")
                    if best_model_state is not None:
                        self.model.load_state_dict(best_model_state)
                    break
        
        self.training_history = {
            'train_losses': train_losses,
            'val_losses': val_losses
        }
        
        # Calculate final metrics - Inverse transform back to original scale
        self.model.eval()
        with torch.no_grad():
            train_pred_scaled = self.model(X_train).numpy().flatten()
            test_pred_scaled = self.model(X_test).numpy().flatten()
            
            # Inverse standardization
            train_pred_unscaled = self.target_scaler.inverse_transform(train_pred_scaled.reshape(-1, 1)).flatten()
            test_pred_unscaled = self.target_scaler.inverse_transform(test_pred_scaled.reshape(-1, 1)).flatten()
            train_actual_unscaled = self.target_scaler.inverse_transform(y_train.numpy()).flatten()
            test_actual_unscaled = self.target_scaler.inverse_transform(y_test.numpy()).flatten()
            
            # If log transform was used, inverse the log transform too
            if self.use_log_transform:
                train_pred = np.expm1(train_pred_unscaled)
                test_pred = np.expm1(test_pred_unscaled)
                train_actual = np.expm1(train_actual_unscaled)
                test_actual = np.expm1(test_actual_unscaled)
            else:
                train_pred = train_pred_unscaled
                test_pred = test_pred_unscaled
                train_actual = train_actual_unscaled
                test_actual = test_actual_unscaled
            
            self.model_metrics = {
                'train_r2': r2_score(train_actual, train_pred),
                'test_r2': r2_score(test_actual, test_pred),
                'train_rmse': np.sqrt(mean_squared_error(train_actual, train_pred)),
                'test_rmse': np.sqrt(mean_squared_error(test_actual, test_pred))
            }
        
        # Store fold results for overfitting analysis
        self.fold_results = fold_results
        
        # Analyze overfitting
        self.analyze_overfitting()
        
        print("\nFinal Model Training Complete!")
        self.print_model_report()
    
    def grid_search(self, param_grid, cv_folds=5, scoring='r2', early_stopping=True, patience=10):
        """
        Perform grid search to find best hyperparameters
        
        Args:
            param_grid (dict): Parameter grid to search
            cv_folds (int): Cross-validation folds
            scoring (str): Scoring metric ('r2' or 'rmse')
            early_stopping (bool): Enable early stopping during grid search
            patience (int): Early stopping patience
        
        Returns:
            dict: Best parameters and results
        """
        print(f"Starting Grid Search with {cv_folds}-fold CV...")
        print(f"Scoring metric: {scoring}")
        
        # Get all parameter combinations
        keys = param_grid.keys()
        values = param_grid.values()
        param_combinations = [dict(zip(keys, v)) for v in product(*values)]
        
        print(f"Total combinations to test: {len(param_combinations)}")
        
        best_score = float('-inf') if scoring == 'r2' else float('inf')
        best_params = None
        results = []
        
        for i, params in enumerate(param_combinations):
            print(f"\nTesting combination {i+1}/{len(param_combinations)}")
            print(f"Parameters: {params}")
            
            # Extract parameters
            hidden_sizes = params.get('hidden_sizes', [64, 32])
            learning_rate = params.get('learning_rate', 0.001)
            epochs = params.get('epochs', 100)
            batch_size = params.get('batch_size', 32)
            dropout_rate = params.get('dropout_rate', 0.2)
            activation = params.get('activation', 'relu')
            
            # Use the same preprocessed data (scalers already fitted)
            X, y = self.preprocess_data()
            X_tensor = torch.FloatTensor(X)
            y_tensor = torch.FloatTensor(y).reshape(-1, 1)
            
            # Cross validation
            kfold = KFold(n_splits=cv_folds, shuffle=True, random_state=42)
            fold_scores = []
            
            for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):
                X_train_fold = X_tensor[train_idx]
                X_val_fold = X_tensor[val_idx]
                y_train_fold = y_tensor[train_idx]
                y_val_fold = y_tensor[val_idx]
                
                # Train model with early stopping
                model = MLPRegressor(X.shape[1], hidden_sizes, dropout_rate, activation)
                criterion = nn.MSELoss()
                optimizer = optim.Adam(model.parameters(), lr=learning_rate)
                
                best_val_loss = float('inf')
                patience_counter = 0
                best_model_state = None
                
                for epoch in range(epochs):
                    model.train()
                    outputs = model(X_train_fold)
                    loss = criterion(outputs, y_train_fold)
                    
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()
                    
                    # Early stopping check
                    if early_stopping:
                        model.eval()
                        with torch.no_grad():
                            val_outputs = model(X_val_fold)
                            val_loss = criterion(val_outputs, y_val_fold)
                            
                            if val_loss.item() < (best_val_loss - 0.001):
                                best_val_loss = val_loss.item()
                                patience_counter = 0
                                best_model_state = model.state_dict().copy()
                            else:
                                patience_counter += 1
                            
                            if patience_counter >= patience:
                                if best_model_state is not None:
                                    model.load_state_dict(best_model_state)
                                break
                
                # Evaluate - Inverse transform for proper scoring in original scale
                model.eval()
                with torch.no_grad():
                    val_pred_scaled = model(X_val_fold).numpy().flatten()
                    
                    # Inverse standardization
                    val_pred_unscaled = self.target_scaler.inverse_transform(val_pred_scaled.reshape(-1, 1)).flatten()
                    val_actual_unscaled = self.target_scaler.inverse_transform(y_val_fold.numpy()).flatten()
                    
                    # If log transform was used, inverse the log transform too
                    if self.use_log_transform:
                        val_pred = np.expm1(val_pred_unscaled)
                        val_actual = np.expm1(val_actual_unscaled)
                    else:
                        val_pred = val_pred_unscaled
                        val_actual = val_actual_unscaled
                    
                    if scoring == 'r2':
                        score = r2_score(val_actual, val_pred)
                    else:  # rmse
                        score = np.sqrt(mean_squared_error(val_actual, val_pred))
                    
                    fold_scores.append(score)
            
            # Calculate average score
            avg_score = np.mean(fold_scores)
            std_score = np.std(fold_scores)
            
            result = {
                'params': params.copy(),
                'mean_score': avg_score,
                'std_score': std_score,
                'fold_scores': fold_scores
            }
            results.append(result)
            
            print(f"{scoring.upper()}: {avg_score:.4f} (+/- {std_score:.4f})")
            
            # Update best parameters
            is_better = (avg_score > best_score) if scoring == 'r2' else (avg_score < best_score)
            if is_better:
                best_score = avg_score
                best_params = params.copy()
                print("*** New best parameters found! ***")
        
        # Sort results
        reverse_sort = True if scoring == 'r2' else False
        results = sorted(results, key=lambda x: x['mean_score'], reverse=reverse_sort)
        
        print("\n" + "="*60)
        print("GRID SEARCH RESULTS")
        print("="*60)
        print(f"Best {scoring.upper()}: {best_score:.4f}")
        print(f"Best parameters: {best_params}")
        
        print(f"\nTop 5 parameter combinations:")
        for i, result in enumerate(results[:5]):
            print(f"{i+1}. {scoring.upper()}: {result['mean_score']:.4f} (+/- {result['std_score']:.4f})")
            print(f"   Parameters: {result['params']}")
        
        return {
            'best_params': best_params,
            'best_score': best_score,
            'results': results
        }
    
    def analyze_overfitting(self):
        """Analyze overfitting and provide recommendations"""
        print("\n" + "="*50)
        print("OVERFITTING ANALYSIS")
        print("="*50)
        
        # Calculate average metrics across folds
        avg_train_r2 = np.mean([fold['train_r2'] for fold in self.fold_results])
        avg_val_r2 = np.mean([fold['val_r2'] for fold in self.fold_results])
        avg_train_rmse = np.mean([fold['train_rmse'] for fold in self.fold_results])
        avg_val_rmse = np.mean([fold['val_rmse'] for fold in self.fold_results])
        
        r2_gap = avg_train_r2 - avg_val_r2
        rmse_gap = avg_val_rmse - avg_train_rmse
        
        print(f"Average Train R²: {avg_train_r2:.4f}")
        print(f"Average Validation R²: {avg_val_r2:.4f}")
        print(f"R² Gap: {r2_gap:.4f}")
        print(f"RMSE Gap: {rmse_gap:.4f}")
        
        # Overfitting detection and recommendations
        if r2_gap > 0.1 or rmse_gap > 0.1:
            print("\n⚠️  OVERFITTING DETECTED!")
            print("\nRecommendations:")
            print("1. Increase dropout rate (current: reduce complexity)")
            print("2. Reduce model complexity (fewer/smaller hidden layers)")
            print("3. Add regularization (L1/L2)")
            print("4. Collect more training data")
            print("5. Reduce training epochs")
            print("6. Use early stopping")
        elif r2_gap > 0.05 or rmse_gap > 0.05:
            print("\n⚠️  MILD OVERFITTING DETECTED")
            print("\nRecommendations:")
            print("1. Slightly increase dropout rate")
            print("2. Monitor training more closely")
            print("3. Consider early stopping")
        else:
            print("\n✅ NO SIGNIFICANT OVERFITTING DETECTED")
            print("Model appears to generalize well!")
    
    def plot_feature_vs_target(self, feature_name, plot_type='points'):
        """
        Plot feature vs target with actual vs predicted values
        
        Args:
            feature_name (str): Name of feature to plot
            plot_type (str): 'points' or 'line'
        """
        if feature_name not in self.feature_names:
            print(f"Feature '{feature_name}' not found. Available features: {self.feature_names}")
            return
        
        if self.model is None:
            print("Model not trained yet. Please train the model first.")
            return
        
        # Get data
        X, y = self.preprocess_data()
        X_tensor = torch.FloatTensor(X)
        
        # Get predictions - Inverse transform to original scale
        self.model.eval()
        with torch.no_grad():
            y_pred_scaled = self.model(X_tensor).numpy().flatten()
            y_pred_unscaled = self.target_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
            
            # If log transform was used, inverse the log transform too
            if self.use_log_transform:
                y_pred = np.expm1(y_pred_unscaled)
            else:
                y_pred = y_pred_unscaled
        
        # Get original scale target values for plotting
        y_original = self.target.values
        
        # Get feature values (original scale)
        feature_idx = self.feature_names.index(feature_name)
        feature_values = self.features[feature_name].values
        
        # Create plot
        plt.figure(figsize=(12, 5))
        
        # Plot 1: Feature vs Actual Target
        plt.subplot(1, 2, 1)
        if plot_type == 'points':
            plt.scatter(feature_values, self.target.values, alpha=0.6, color='blue')
        else:
            sorted_idx = np.argsort(feature_values)
            plt.plot(feature_values[sorted_idx], self.target.values[sorted_idx], color='blue')
        
        plt.xlabel(feature_name)
        plt.ylabel(f'Actual {self.target_column}')
        plt.title(f'{feature_name} vs Actual {self.target_column}')
        plt.grid(True, alpha=0.3)
        
        # Plot 2: Actual vs Predicted (both in original scale)
        plt.subplot(1, 2, 2)
        if plot_type == 'points':
            plt.scatter(y_original, y_pred, alpha=0.6, color='red')
        else:
            sorted_idx = np.argsort(y_original)
            plt.plot(y_original[sorted_idx], y_pred[sorted_idx], color='red')
        
        # Perfect prediction line
        min_val, max_val = min(y_original.min(), y_pred.min()), max(y_original.max(), y_pred.max())
        plt.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='Perfect Prediction')
        
        plt.xlabel(f'Actual {self.target_column}')
        plt.ylabel(f'Predicted {self.target_column}')
        plt.title('Actual vs Predicted (Original Scale)')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def plot_training_history(self):
        """Plot training history"""
        if not self.training_history['train_losses']:
            print("No training history available. Train the model first.")
            return
        
        plt.figure(figsize=(10, 4))
        
        plt.subplot(1, 2, 1)
        plt.plot(self.training_history['train_losses'], label='Train Loss')
        plt.plot(self.training_history['val_losses'], label='Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Training History')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.subplot(1, 2, 2)
        epochs = len(self.training_history['train_losses'])
        recent_epochs = max(10, epochs // 4)
        plt.plot(self.training_history['train_losses'][-recent_epochs:], label='Train Loss')
        plt.plot(self.training_history['val_losses'][-recent_epochs:], label='Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title(f'Last {recent_epochs} Epochs')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def predict(self, feature_values):
        """
        Make prediction with manually input feature values
        
        Args:
            feature_values (dict): Dictionary with feature names as keys and values
        
        Returns:
            float: Predicted value (original scale)
        """
        if self.model is None:
            print("Model not trained yet. Please train the model first.")
            return None
        
        if not isinstance(feature_values, dict):
            print("feature_values must be a dictionary with feature names as keys")
            return None
        
        # Check if all features are provided
        missing_features = set(self.feature_names) - set(feature_values.keys())
        if missing_features:
            print(f"Missing features: {missing_features}")
            return None
        
        # Create input array
        input_array = np.array([feature_values[feature] for feature in self.feature_names]).reshape(1, -1)
        
        # Apply same preprocessing as training (both scalers fitted on training data)
        input_data = input_array.copy()
        
        # Apply log transform if it was used during training
        if self.use_log_transform:
            input_data = np.log1p(np.abs(input_data))
        
        # Apply feature scaling
        input_scaled = self.feature_scaler.transform(input_data)
        input_tensor = torch.FloatTensor(input_scaled)
        
        # Make prediction
        self.model.eval()
        with torch.no_grad():
            pred_scaled = self.model(input_tensor).numpy()[0, 0]
            # Inverse standardization
            pred_unscaled = self.target_scaler.inverse_transform([[pred_scaled]])[0, 0]
            
            # If log transform was used, inverse the log transform too
            if self.use_log_transform:
                pred_original = np.expm1(pred_unscaled)
            else:
                pred_original = pred_unscaled
        
        print(f"Input features: {feature_values}")
        print(f"Predicted {self.target_column}: {pred_original:.4f}")
        
        return pred_original
    
    def print_model_report(self):
        """Print comprehensive model report"""
        print("\n" + "="*50)
        print("MODEL PERFORMANCE REPORT")
        print("="*50)
        print(f"Features used: {len(self.feature_names)}")
        print(f"Features: {self.feature_names}")
        print(f"Log transformation: {'Enabled' if self.use_log_transform else 'Disabled'}")
        if self.dropped_features:
            print(f"Dropped features: {self.dropped_features}")
        
        print(f"\nFinal Model Metrics:")
        print(f"Train R²: {self.model_metrics['train_r2']:.4f}")
        print(f"Test R²: {self.model_metrics['test_r2']:.4f}")
        print(f"Train RMSE: {self.model_metrics['train_rmse']:.4f}")
        print(f"Test RMSE: {self.model_metrics['test_rmse']:.4f}")
        
        # Performance interpretation
        test_r2 = self.model_metrics['test_r2']
        print(f"\nModel Performance Interpretation:")
        if test_r2 >= 0.9:
            print("🌟 Excellent performance")
        elif test_r2 >= 0.8:
            print("✅ Good performance")
        elif test_r2 >= 0.6:
            print("⚠️  Moderate performance")
        else:
            print("❌ Poor performance - consider model improvements")

# # Example usage and demonstration
# if __name__ == "__main__":
#     # Create synthetic dataset for demo
#     np.random.seed(42)
#     n_samples = 1000
#     synthetic_data = {
#         'feature1': np.random.randn(n_samples) * 10 + 50,
#         'feature2': np.random.randn(n_samples) * 5 + 20,
#         'feature3': np.random.randn(n_samples) * 15 + 100,
#         'feature4': np.random.randn(n_samples) * 3 + 5,
#     }
#     synthetic_data['target'] = (
#         2 * synthetic_data['feature1'] + 
#         1.5 * synthetic_data['feature2'] + 
#         0.8 * synthetic_data['feature3'] + 
#         3 * synthetic_data['feature4'] + 
#         np.random.randn(n_samples) * 10
#     )
    
#     synthetic_df = pd.DataFrame(synthetic_data)
#     synthetic_df.to_csv('synthetic_data.csv', index=False)
    
#     # Initialize model - NOW WITH TOGGLEABLE LOG TRANSFORM
#     mlp_manager = MLPModelManager('synthetic_data.csv', 'target', use_log_transform=False)
    
#     # Drop features manually
#     mlp_manager.drop_features(['feature4'])
    
#     # Example 1: Basic training without log transform
#     mlp_manager.train_model()
    
#     print("\n" + "="*60)
#     print("TOGGLEABLE LOG TRANSFORMATION:")
#     print("="*60)
#     print("# Without log transform (default)")
#     print("mlp_manager = MLPModelManager('data.csv', 'target', use_log_transform=False)")
#     print("")
#     print("# With log transform (for skewed data)")
#     print("mlp_manager = MLPModelManager('data.csv', 'target', use_log_transform=True)")
    
#     print("\n" + "="*60)
#     print("MANUAL PARAMETER ADJUSTMENT:")
#     print("="*60)
#     print("mlp_manager.train_model(")
#     print("    hidden_sizes=[64, 32],     # [16] = simple, [128,64,32] = complex")
#     print("    learning_rate=0.001,       # 0.0001 = slow, 0.01 = fast")
#     print("    epochs=200,                # 50 = quick, 500 = thorough")
#     print("    batch_size=32,             # 8 = precise, 128 = fast")
#     print("    dropout_rate=0.2,          # 0.1 = light, 0.5 = heavy")
#     print("    k_folds=5,                 # 3 = quick, 10 = thorough")
#     print("    activation='relu',         # relu, tanh, sigmoid, leaky_relu, elu, gelu, swish, mish")
#     print("    early_stopping=True,       # Enable/disable early stopping")
#     print("    patience=10,               # Early stopping patience")
#     print("    print_every=20             # Progress updates frequency")
#     print(")")
    
#     print("\n" + "="*60)
#     print("WHEN TO USE LOG TRANSFORMATION:")
#     print("="*60)
#     print("✅ Use log transform (use_log_transform=True) when:")
#     print("  - Target values are heavily skewed (right-tailed)")
#     print("  - Wide range of values (e.g., 1 to 1,000,000)")
#     print("  - Housing prices, population data, financial data")
#     print("  - Error distributions are non-normal")
#     print("")
#     print("❌ Don't use log transform (use_log_transform=False) when:")
#     print("  - Target values are already normally distributed")
#     print("  - Small range of values")
#     print("  - Data contains many zeros or negative values")
#     print("  - Classification tasks")
    
#     print("\n" + "="*60)
#     print("GRID SEARCH USAGE:")
#     print("="*60)
#     print("param_grid = {")
#     print("    'hidden_sizes': [[32], [64, 32], [128, 64]],")
#     print("    'learning_rate': [0.001, 0.01],")
#     print("    'activation': ['relu', 'tanh']")
#     print("}")
#     print("best_results = mlp_manager.grid_search(param_grid)")
#     print("mlp_manager.train_model(**best_results['best_params'])")
    
#     print("\nAVAILABLE ACTIVATION FUNCTIONS:")
#     print("relu, tanh, sigmoid, leaky_relu, elu, gelu, swish, mish")
    
#     # Plot and predict
#     mlp_manager.plot_training_history()
#     mlp_manager.plot_feature_vs_target('feature1', plot_type='points')
    
#     prediction = mlp_manager.predict({
#         'feature1': 55.0,
#         'feature2': 25.0,
#         'feature3': 110.0
#     })
